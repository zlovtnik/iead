name: Quality Assurance Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run quality checks daily at 2 AM UTC
    - cron: '0 2 * * *'
permissions:
  contents: read
  security-events: write

env:
  NODE_VERSION: '18'
  LUA_VERSION: '5.1'

jobs:
  # …
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
           echo "Error: OpenResty failed to start"
           exit 1
         fiuses: actions/checkout@v4
      
    - name: Setup Lua Environment
      uses: leafo/gh-actions-lua@v10
      with:
        luaVersion: ${{ env.LUA_VERSION }}
        
    - name: Setup LuaRocks
      uses: leafo/gh-actions-luarocks@v4
      
    - name: Install Lua Dependencies
      run: |
        luarocks install luacheck
        luarocks install busted
        luarocks install luacov
        
    - name: Install OpenResty Dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y openresty
        # If schema.lua contains Lua code that generates SQL:
        lua src/db/schema.lua | sqlite3 church_management.db || true
        lua src/db/schema.lua | sqlite3 demo_church_management.db || true
      run: |
        sudo apt-get install -y sqlite3
        # If schema.lua contains Lua code that generates SQL:
        lua src/db/schema.lua | sqlite3 church_management.db || true
        # Or if you have a separate SQL file:
        # sqlite3 church_management.db < src/db/schema.sql || true
        
    - name: Run Lua Static Analysis
      run: luacheck src/ --formatter=github
      
    - name: Run Backend Unit Tests
      run: lua scripts/run_comprehensive_tests.lua --json --output test-results.json --coverage --verbose
      
    - name: Run Security Tests
      run: lua scripts/simple_security_test.lua
      
    - name: Run Performance Tests
      run: lua scripts/performance_test.lua
      continue-on-error: true
      
    - name: Run Security Audit
      run: bash scripts/security_audit.sh
      continue-on-error: true
      
    - name: Generate Coverage Report
      run: lua scripts/coverage_analyzer.lua --html --output coverage-report.html --json --output coverage-summary.json
      continue-on-error: true
      
    - name: Upload Backend Test Results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: backend-test-results
        path: |
          test-results.json
          coverage-report.html
          coverage-summary.json
          **/*.log

  frontend-quality:
    name: Frontend Quality Checks
    runs-on: ubuntu-latest
    
    defaults:
      run:
        working-directory: ./public
    
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: public/package-lock.json
        
    - name: Install Dependencies
      run: npm ci
      
    - name: Run Type Checking
      run: npx tsc --noEmit
      
    - name: Run ESLint
      run: npm run lint
      
    - name: Run Tests with Coverage
      run: npm run test:coverage
      
    - name: Run Bundle Analysis
      run: node ../scripts/bundle_analyzer.mjs
      continue-on-error: true
      
    - name: Upload Coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        directory: ./public/coverage
        flags: frontend
        
    - name: Upload Frontend Test Results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: frontend-test-results
        path: |
          public/coverage/
          public/dist/
          bundle-analysis.json

  security-audit:
    name: Security Audit
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: public/package-lock.json
        
    - name: Install Frontend Dependencies
      run: cd public && npm ci
      
    - name: Run npm audit
      run: cd public && npm audit --audit-level=moderate
      continue-on-error: true
      
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
        
    - name: Upload Trivy scan results to GitHub Security tab
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [backend-quality, frontend-quality]
    
    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
          
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      
    - name: Setup Complete Environment
      run: |
        sudo apt-get update
        sudo apt-get install -y openresty sqlite3 lua5.1 luarocks
        luarocks install busted
        
    - name: Setup Database
      run: |
        sqlite3 church_management.db ".read src/db/schema.sql" || true
        sqlite3 demo_church_management.db ".read src/db/schema.sql" || true
        
    - name: Setup Node.js and Frontend
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: public/package-lock.json
        
    - name: Install Frontend Dependencies
      run: cd public && npm ci
      
    - name: Build Frontend
      run: cd public && npm run build
      
    - name: Start Application Services
      run: |
        # Start OpenResty in background
        openresty -p . -c nginx.conf &
        
        # Wait for services to be ready
        sleep 5
        
    - name: Run API Integration Tests
      run: lua scripts/api_test.lua
      
    - name: Run Full System Tests
      run: lua scripts/test_auth_middleware_integration.lua
      
    - name: Stop Services
      run: |
        pkill -f openresty || true

  performance-benchmarks:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || contains(github.event.head_commit.message, '[benchmark]')
    
    steps:
    - name: Checkout Code
      uses: actions/checkout@v4
      
    - name: Setup Environment
      run: |
        sudo apt-get update
        sudo apt-get install -y openresty sqlite3 lua5.1 luarocks
        luarocks install busted
        
    - name: Setup Database with Test Data
      run: |
        sqlite3 church_management.db < src/db/schema.lua
        lua scripts/simple_demo.lua
        
    - name: Start Services
      run: |
        openresty -p . -c nginx.conf &
        sleep 5
        
    - name: Run Performance Benchmarks
      run: |
        lua scripts/performance_demo.lua > performance-results.txt
        lua scripts/performance_test.lua >> performance-results.txt
        
    - name: Upload Performance Results
      uses: actions/upload-artifact@v4
      run: |
        if [[ -f src/db/schema.lua ]]; then
          lua src/db/schema.lua | sqlite3 church_management.db
          lua src/db/schema.lua | sqlite3 demo_church_management.db
        else
          sqlite3 church_management.db < src/db/schema.sql
          sqlite3 demo_church_management.db < src/db/schema.sql
        fi
        lua scripts/simple_demo.lua
    - name: Comment Performance Results on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const results = fs.readFileSync('performance-results.txt', 'utf8');
          
          await github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: `## Performance Benchmark Results\n\n\`\`\`\n${results}\n\`\`\``
          });

  quality-gate:
    name: Quality Gate
    runs-on: ubuntu-latest
    needs: [backend-quality, frontend-quality, security-audit, integration-tests]
    if: always()
    
    steps:
    - name: Check Quality Gate
      run: |
        echo "Backend Quality: ${{ needs.backend-quality.result }}"
        echo "Frontend Quality: ${{ needs.frontend-quality.result }}"
        echo "Security Audit: ${{ needs.security-audit.result }}"
        echo "Integration Tests: ${{ needs.integration-tests.result }}"
        
        # Fail if any critical job failed
        if [[ "${{ needs.backend-quality.result }}" == "failure" ]]; then
          echo "❌ Backend quality checks failed"
          exit 1
        fi
        
        if [[ "${{ needs.frontend-quality.result }}" == "failure" ]]; then
          echo "❌ Frontend quality checks failed"
          exit 1
        fi
        
        if [[ "${{ needs.integration-tests.result }}" == "failure" ]]; then
          echo "❌ Integration tests failed"
          exit 1
        fi
        
        echo "✅ All quality checks passed!"

  notify-status:
    name: Notify Status
    runs-on: ubuntu-latest
    needs: [quality-gate]
    if: always() && github.event_name == 'schedule'
    
    steps:
    - name: Notify Success
      if: needs.quality-gate.result == 'success'
      run: |
        echo "✅ Daily quality checks passed successfully!"
        # Add webhook notification here if needed
        
    - name: Notify Failure
      if: needs.quality-gate.result == 'failure'
      run: |
        echo "❌ Daily quality checks failed!"
        # Add webhook notification here if needed
        exit 1
